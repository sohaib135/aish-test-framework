# core/explainer_langchain.py
import os
import sys
import time # To simulate API call delay

# Add project root to Python path if this script is run directly for testing
# script_dir = os.path.dirname(os.path.abspath(__file__))
# project_root = os.path.abspath(os.path.join(script_dir, '..'))
# if project_root not in sys.path:
#     sys.path.append(project_root)

# In a real LangChain setup, you'd import from langchain libraries:
# from langchain_openai import ChatOpenAI
# from langchain_core.prompts import ChatPromptTemplate
# from langchain_core.output_parsers import StrOutputParser

# For now, we'll simulate the LLM interaction.
# You would replace this with your actual LangChain setup and LLM calls.

class LogExplainer:
    """
    Simulates a LangChain-based log explainer.
    In a real scenario, this would interact with an LLM.
    """
    def __init__(self, api_key_env_var="OPENAI_API_KEY"):
        # In a real setup, you'd initialize your LLM client here.
        # self.api_key = os.getenv(api_key_env_var)
        # if not self.api_key:
        #     print(f"[WARN] Explainer: Environment variable {api_key_env_var} not set. LLM calls will be simulated.")
        #     self.llm = None
        # else:
        #     self.llm = ChatOpenAI(openai_api_key=self.api_key, model_name="gpt-3.5-turbo") # Or your preferred model
        # self.prompt_template = ChatPromptTemplate.from_messages([
        #     ("system", "You are an expert system log analyst. Provide a concise explanation, potential causes, and actionable suggestions for the given log entry. Focus on CI/CD pipeline failures."),
        #     ("user", "Analyze this log: {log_text}")
        # ])
        # self.output_parser = StrOutputParser()
        # self.chain = self.prompt_template | self.llm | self.output_parser
        print("[INFO] LogExplainer initialized (Simulated Mode).")

    def get_explanation(self, log_text: str) -> dict:
        """
        Provides an explanation for a given log text.
        Currently simulates an LLM call.
        """
        print(f"[INFO] Explainer: Received log for explanation: \"{log_text[:100]}...\"")
        # Simulate API call delay
        time.sleep(0.1) # Reduced delay for faster dashboard response

        # --- SIMULATED LLM RESPONSE ---
        # Replace this with actual self.chain.invoke({"log_text": log_text}) if using real LangChain
        if "file not found" in log_text.lower() or "no such file" in log_text.lower():
            return {
                "original_log": log_text,
                "explanation": "The system reports that a required file or directory could not be located. This is a common issue in CI/CD pipelines when paths are misconfigured, dependencies are not correctly installed, or artifacts from previous steps are missing.",
                "potential_causes": [
                    "Incorrect file/directory path in script or configuration.",
                    "File was not generated by a previous step in the pipeline.",
                    "Permissions issues preventing access to the file/directory.",
                    "Build agent environment is missing expected dependencies or tools."
                ],
                "suggested_actions": [
                    "Verify all file and directory paths for correctness and case-sensitivity.",
                    "Ensure that previous pipeline steps that generate this file completed successfully.",
                    "Check file system permissions for the user/agent running the pipeline.",
                    "Confirm that all necessary dependencies and build tools are installed on the agent."
                ],
                "simulated": True
            }
        elif "connection timeout" in log_text.lower() or "connection reset by peer" in log_text.lower():
            return {
                "original_log": log_text,
                "explanation": "A network connection attempt failed to complete within the allocated time, or an existing connection was forcibly closed. This often points to network instability, a non-responsive service, or firewall restrictions.",
                "potential_causes": [
                    "Target service is down or unreachable.",
                    "Network latency or packet loss between client and server.",
                    "Firewall rules blocking the connection.",
                    "Service is overloaded and cannot accept new connections.",
                    "Incorrect host, port, or protocol in connection string."
                ],
                "suggested_actions": [
                    "Verify the target service is running and accessible (e.g., ping, telnet).",
                    "Check network stability and for any ongoing network outages.",
                    "Review firewall configurations on both client and server sides.",
                    "Investigate server load and consider increasing connection timeout settings if appropriate.",
                    "Double-check connection parameters (hostname, port, credentials)."
                ],
                "simulated": True
            }
        elif "kernel panic" in log_text.lower():
            return {
                "original_log": log_text,
                "explanation": "A Kernel Panic is a critical system error detected by the operating system's kernel, from which it cannot safely recover. This usually leads to a system halt.",
                "potential_causes": [
                    "Hardware malfunction (RAM, CPU, disk).",
                    "Corrupted filesystem or critical system files.",
                    "Incompatible or faulty kernel module/driver.",
                    "Severe software bug at a very low level."
                ],
                "suggested_actions": [
                    "Reboot the system; if persistent, investigate hardware diagnostics.",
                    "Check filesystem integrity (e.g., fsck).",
                    "Review recently installed/updated drivers or kernel modules.",
                    "Analyze kernel crash dump if available."
                ],
                "simulated": True
            }
        elif "null pointer dereference" in log_text.lower() or "access violation" in log_text.lower() or "segmentation fault" in log_text.lower():
            return {
                "original_log": log_text,
                "explanation": "The application attempted to access a memory location that is invalid (e.g., null or out of bounds), leading to a crash. This is a common programming error.",
                "potential_causes": [
                    "Bug in the application code (e.g., using an uninitialized pointer/reference).",
                    "Memory corruption from another part of the application.",
                    "Incorrect use of third-party libraries.",
                    "Race conditions in multi-threaded applications."
                ],
                "suggested_actions": [
                    "Review the stack trace to identify the exact location of the crash in the code.",
                    "Use a debugger to inspect variable states at the time of the crash.",
                    "Analyze recent code changes for potential bugs.",
                    "Employ static analysis tools to detect potential memory errors."
                ],
                "simulated": True
            }
        # Add more rule-based explanations or a generic one
        else:
            return {
                "original_log": log_text,
                "explanation": "The nature of this log entry is not immediately classifiable by predefined rules. It may represent a generic error, a specific application message, or an informational log.",
                "potential_causes": ["Varied, depending on the application and context."],
                "suggested_actions": [
                    "Review the log in conjunction with surrounding log entries for context.",
                    "Consult application-specific documentation or knowledge bases.",
                    "If it's a recurring unknown error, consider adding a specific parsing or explanation rule."
                ],
                "simulated": True
            }

# For standalone testing of this module
if __name__ == "__main__":
    explainer = LogExplainer()
    
    test_logs = [
        "Kernel panic: Unable to mount root filesystem",
        "Database connection timeout during query execution",
        "ERROR FileProcessor - file not found: /input/data.csv",
        "Crash in rendering engine: Null pointer dereference",
        "INFO: User logged in successfully." # A more generic one
    ]

    for log in test_logs:
        explanation_result = explainer.get_explanation(log)
        print(f"\n--- Explanation for: \"{log}\" ---")
        print(f"  Explanation: {explanation_result.get('explanation')}")
        print(f"  Causes: {', '.join(explanation_result.get('potential_causes', []))}")
        print(f"  Suggestions: {', '.join(explanation_result.get('suggested_actions', []))}")